{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T22:03:30.922953Z",
     "start_time": "2020-12-16T22:03:30.898139Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(To do once per environment)\n",
    "Clone the package from https://github.com/ClemenceK/bpifrance_deeptech_analysis\n",
    "(You probably have already done it if you have this notebook!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T14:30:04.483621Z",
     "start_time": "2020-12-16T14:29:52.468971Z"
    }
   },
   "outputs": [],
   "source": [
    "! pip install ..\n",
    "# or if you prefer move to that project folder (one step above this notebook, where the setup.py is) in your terminal \n",
    "# and install from there using pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone in the same place the package from: https://github.com/ClemenceK/deep4deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T10:35:49.924200Z",
     "start_time": "2020-12-16T10:35:47.187261Z"
    }
   },
   "outputs": [],
   "source": [
    "# install the bpifrance_deeptech_analysis package from hereâ€¦\n",
    "! pip install ../../deep4deep/\n",
    "# or if you prefer move to that project folder (where the setup.py is) in your terminal \n",
    "# and install from there using pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T10:42:13.876028Z",
     "start_time": "2020-12-16T10:42:13.868848Z"
    }
   },
   "outputs": [],
   "source": [
    "#this can be used to test if the import worked\n",
    "from deep4deep.utils import simple_time_tracker\n",
    "\n",
    "@simple_time_tracker\n",
    "def test():\n",
    "    print(\"It works if below is printed something like: test 0.0, or another figure\")\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local files preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the bpifrance_deeptech_analysis project folder, create a .env file (where the setup.py is), and in this file write:\n",
    "\n",
    "DEALROOMAPIKEY= 'your_key' (replace by your key)\n",
    "\n",
    "(this is to avoid loading your key on github, and .env should be mentionned in .gitignore to not be uploaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In bpifrance_deeptech_analysis, create a data and raw_data local folders, with inside:\n",
    "[TODO if needed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the base data from dealroom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get data from Dealroom with the functions written by the former Wagon team, either by : \n",
    "\n",
    "- ID : list all the companies Dealroom ID you want to analyse in 3 different csv according to the companies classification (deeptech, non_deeptech, almost_deeptech) and save these three csv in the folder \"data\". \n",
    "Use the function getdata.getfulldata() (former wagon team function) to get the new companies data from Dealroom and save the csv in the folder \"rawdata\"\n",
    "\n",
    "- name : use the function \"company_search\" -> to be automatized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T22:03:42.594652Z",
     "start_time": "2020-12-16T22:03:41.786108Z"
    }
   },
   "outputs": [],
   "source": [
    "from bpideep.getdata import company_search\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to get Dealroom data for our 9 companies : run it only if you need to get new data + save the new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T15:11:37.584701Z",
     "start_time": "2020-12-16T15:11:35.317593Z"
    },
    "collapsed": true
   },
   "source": [
    "new = [\"verkor\", \"angell\", \"carbios\",\"mastergrid\",\"pasqal\",\"gourmey\", \"Epigene Labs\",\"SpaceSense\",\"Kraaft\"]\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for company in new :\n",
    "    \n",
    "    tmp = company_search(company)\n",
    "    df = pd.concat([df, tmp], ignore_index=True)\n",
    "\n",
    "df.to_csv(\"demo_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T22:03:43.588380Z",
     "start_time": "2020-12-16T22:03:43.538068Z"
    }
   },
   "outputs": [],
   "source": [
    "new_data = pd.read_csv(\"../bpideep/rawdata/demo_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select the needed columns to make the data analysis easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T22:03:44.191348Z",
     "start_time": "2020-12-16T22:03:44.169323Z"
    }
   },
   "outputs": [],
   "source": [
    "new_data = new_data[[\"id\", \"name\", \"total_funding_source\", \"employees\",\n",
    "                 \"employees_latest\", \"launch_year\", \"growth_stage\", \"linkedin_url\", \"industries\", \"investors\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Add the nb_patents to the new_data. \n",
    "\n",
    "In our example, as we don't have an extract from Google Patents Search, we will only create a column \"nb_patents\" with 0 in it.\n",
    "\n",
    "NB : To use the function GetCleanData.get_clean_data(), don't forget to save the csv files (for the patents and LinkedIn data) in the folder \"data\", and replace the name of the csv if different from the name written in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T22:03:44.688905Z",
     "start_time": "2020-12-16T22:03:44.664852Z"
    }
   },
   "outputs": [],
   "source": [
    "new_data[\"nb_patents\"] = np.full([new_data.shape[0], 1], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create a new column \"age\" to get the age of the company thanks to the column \"launch_year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T22:03:45.449975Z",
     "start_time": "2020-12-16T22:03:45.418659Z"
    }
   },
   "outputs": [],
   "source": [
    "new_data[\"age\"] = 2020 - new_data.launch_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create a new feature \"investors_type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T22:03:46.520654Z",
     "start_time": "2020-12-16T22:03:46.476041Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-b62600479cfc>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_data[\"investors_type\"] = fund_investors(new_data[[\"investors_type\"]])\n"
     ]
    }
   ],
   "source": [
    "from bpideep.GetCleanData import load_json_field, get_health, fund_investors, investors_type\n",
    "\n",
    "new_data[\"investors\"] = new_data[\"investors\"].apply(load_json_field)\n",
    "new_data[\"investors_type\"] = pd.DataFrame(new_data[\"investors\"].apply(lambda row: investors_type(row)))\n",
    "new_data[\"investors_type\"] = fund_investors(new_data[[\"investors_type\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Create a new feature \"health_industry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T22:03:47.865031Z",
     "start_time": "2020-12-16T22:03:47.841290Z"
    }
   },
   "outputs": [],
   "source": [
    "new_data[\"health_industry\"] = pd.DataFrame(get_health(new_data[\"industries\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. To use the pipeline, name of the feature columns should be the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T22:03:48.550955Z",
     "start_time": "2020-12-16T22:03:48.472550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>total_funding_source</th>\n",
       "      <th>employees</th>\n",
       "      <th>employees_clean</th>\n",
       "      <th>launch_year_clean</th>\n",
       "      <th>growth_stage_imputed</th>\n",
       "      <th>linkedin_url</th>\n",
       "      <th>industries</th>\n",
       "      <th>investors</th>\n",
       "      <th>nb_patents</th>\n",
       "      <th>age</th>\n",
       "      <th>investors_type</th>\n",
       "      <th>health_industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1985985</td>\n",
       "      <td>Verkor</td>\n",
       "      <td>0</td>\n",
       "      <td>2-10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>seed</td>\n",
       "      <td>https://www.linkedin.com/company/verkor/</td>\n",
       "      <td>[{'id': 100023, 'name': 'energy'}]</td>\n",
       "      <td>{'items': [{'id': 869605, 'name': 'EIT InnoEne...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1841152</td>\n",
       "      <td>Angell</td>\n",
       "      <td>10000000</td>\n",
       "      <td>11-50</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>early growth</td>\n",
       "      <td>https://www.linkedin.com/company/angell</td>\n",
       "      <td>[{'id': 100111, 'name': 'transportation'}]</td>\n",
       "      <td>{'items': [{'id': 1476722, 'name': 'Groupe SEB...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>924274</td>\n",
       "      <td>Carbios</td>\n",
       "      <td>7400000</td>\n",
       "      <td>11-50</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>early growth</td>\n",
       "      <td>https://www.linkedin.com/company/carbios</td>\n",
       "      <td>[{'id': 100023, 'name': 'energy'}]</td>\n",
       "      <td>{'items': [{'id': 24770, 'name': 'Truffle Capi...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2434315</td>\n",
       "      <td>Mastergrid</td>\n",
       "      <td>0</td>\n",
       "      <td>51-200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>late growth</td>\n",
       "      <td>https://www.linkedin.com/company/mastergrid/</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'items': [], 'total': 0}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1685632</td>\n",
       "      <td>Pasqal</td>\n",
       "      <td>0</td>\n",
       "      <td>11-50</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>early growth</td>\n",
       "      <td>https://www.linkedin.com/company/pasqal</td>\n",
       "      <td>[{'id': 100120, 'name': 'semiconductors'}]</td>\n",
       "      <td>{'items': [{'id': 1218398, 'name': 'Quantonati...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1769618</td>\n",
       "      <td>Gourmey</td>\n",
       "      <td>50000</td>\n",
       "      <td>11-50</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>early growth</td>\n",
       "      <td>https://www.linkedin.com/company/gourmey</td>\n",
       "      <td>[{'id': 100008, 'name': 'food'}]</td>\n",
       "      <td>{'items': [{'id': 871041, 'name': 'European In...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1757959</td>\n",
       "      <td>Epigene Labs</td>\n",
       "      <td>1400000</td>\n",
       "      <td>11-50</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>early growth</td>\n",
       "      <td>https://www.linkedin.com/company/epigene-labs</td>\n",
       "      <td>[{'id': 1254, 'name': 'health'}]</td>\n",
       "      <td>{'items': [{'id': 885471, 'name': 'Agoranov', ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1814695</td>\n",
       "      <td>SpaceSense</td>\n",
       "      <td>0</td>\n",
       "      <td>2-10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>seed</td>\n",
       "      <td>https://www.linkedin.com/company/spacesense-co</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'items': [], 'total': 0}</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1570787</td>\n",
       "      <td>Kraaft</td>\n",
       "      <td>0</td>\n",
       "      <td>11-50</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>early growth</td>\n",
       "      <td>https://www.linkedin.com/company/kraaft-co</td>\n",
       "      <td>[{'id': 100147, 'name': 'enterprise software'}]</td>\n",
       "      <td>{'items': [{'id': 965241, 'name': 'OPEO Startu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id          name  total_funding_source employees  employees_clean  \\\n",
       "0  1985985        Verkor                     0      2-10              9.0   \n",
       "1  1841152        Angell              10000000     11-50             25.0   \n",
       "2   924274       Carbios               7400000     11-50             37.0   \n",
       "3  2434315    Mastergrid                     0    51-200              NaN   \n",
       "4  1685632        Pasqal                     0     11-50             14.0   \n",
       "5  1769618       Gourmey                 50000     11-50             18.0   \n",
       "6  1757959  Epigene Labs               1400000     11-50             11.0   \n",
       "7  1814695    SpaceSense                     0      2-10              4.0   \n",
       "8  1570787        Kraaft                     0     11-50             12.0   \n",
       "\n",
       "   launch_year_clean growth_stage_imputed  \\\n",
       "0               2020                 seed   \n",
       "1               2018         early growth   \n",
       "2               2011         early growth   \n",
       "3               2019          late growth   \n",
       "4               2019         early growth   \n",
       "5               2019         early growth   \n",
       "6               2019         early growth   \n",
       "7               2018                 seed   \n",
       "8               2019         early growth   \n",
       "\n",
       "                                     linkedin_url  \\\n",
       "0        https://www.linkedin.com/company/verkor/   \n",
       "1         https://www.linkedin.com/company/angell   \n",
       "2        https://www.linkedin.com/company/carbios   \n",
       "3    https://www.linkedin.com/company/mastergrid/   \n",
       "4         https://www.linkedin.com/company/pasqal   \n",
       "5        https://www.linkedin.com/company/gourmey   \n",
       "6   https://www.linkedin.com/company/epigene-labs   \n",
       "7  https://www.linkedin.com/company/spacesense-co   \n",
       "8      https://www.linkedin.com/company/kraaft-co   \n",
       "\n",
       "                                        industries  \\\n",
       "0               [{'id': 100023, 'name': 'energy'}]   \n",
       "1       [{'id': 100111, 'name': 'transportation'}]   \n",
       "2               [{'id': 100023, 'name': 'energy'}]   \n",
       "3                                               []   \n",
       "4       [{'id': 100120, 'name': 'semiconductors'}]   \n",
       "5                 [{'id': 100008, 'name': 'food'}]   \n",
       "6                 [{'id': 1254, 'name': 'health'}]   \n",
       "7                                               []   \n",
       "8  [{'id': 100147, 'name': 'enterprise software'}]   \n",
       "\n",
       "                                           investors  nb_patents  age  \\\n",
       "0  {'items': [{'id': 869605, 'name': 'EIT InnoEne...           0    0   \n",
       "1  {'items': [{'id': 1476722, 'name': 'Groupe SEB...           0    2   \n",
       "2  {'items': [{'id': 24770, 'name': 'Truffle Capi...           0    9   \n",
       "3                          {'items': [], 'total': 0}           0    1   \n",
       "4  {'items': [{'id': 1218398, 'name': 'Quantonati...           0    1   \n",
       "5  {'items': [{'id': 871041, 'name': 'European In...           0    1   \n",
       "6  {'items': [{'id': 885471, 'name': 'Agoranov', ...           0    1   \n",
       "7                          {'items': [], 'total': 0}           0    2   \n",
       "8  {'items': [{'id': 965241, 'name': 'OPEO Startu...           0    1   \n",
       "\n",
       "  investors_type  health_industry  \n",
       "0              1                0  \n",
       "1              0                0  \n",
       "2              1                0  \n",
       "3              0                0  \n",
       "4              1                0  \n",
       "5              1                0  \n",
       "6              1                1  \n",
       "7              0                0  \n",
       "8              1                0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.rename(columns={\"employees_latest\": \"employees_clean\", \"launch_year\": \"launch_year_clean\", \"growth_stage\": \"growth_stage_imputed\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping and adding the LinkedIn data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to generate scripts for webscraper and scrape LinkedIn -> live demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T11:24:09.889297Z",
     "start_time": "2020-12-16T11:24:09.862027Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prior to calling the function \"build employee_df\", the csv containing the scrapped data should be included\n",
    "# in a folder 'bpi_deep/scraping_data/companies_people/'\n",
    "from bpideep.process_scraped_data import build_employee_df, process_employee_data\n",
    "df_employees= process_employee_data(build_employee_df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T11:24:51.337938Z",
     "start_time": "2020-12-16T11:24:51.324225Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Example of the content of the employee dataframe after processing\n",
    "df_employees.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, generate scripts for profile scraping on LinkedIn and scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T11:28:29.747490Z",
     "start_time": "2020-12-16T11:28:29.737778Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prior to calling the function \"open_founder_profile_files\", the csv containing the scrapped data from founders\n",
    "# should be included in a folder 'bpi_deep/scraping_data/founders_files/'\n",
    "from bpideep.process_scraped_data import open_founder_profile_files, inline_profile\n",
    "from bpideep.process_scraped_data import build_founders_dataframe, generate_founders_features\n",
    "df_founders_raw = open_founder_profile_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T11:28:41.714285Z",
     "start_time": "2020-12-16T11:28:41.090417Z"
    }
   },
   "outputs": [],
   "source": [
    "#The function \"build_founders_dataframe\" processes the raw df and returns a df with one line per founder\n",
    "#The function \"generate_founders_features\" generates the new relevant features such as \"founder_has_phd\" etc..\n",
    "df_founders = generate_founders_features(build_founders_dataframe(df_founders_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T11:28:52.474896Z",
     "start_time": "2020-12-16T11:28:52.445559Z"
    }
   },
   "outputs": [],
   "source": [
    "df_founders.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T11:29:42.307664Z",
     "start_time": "2020-12-16T11:29:42.276463Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finally, we merge founders to the full employee DF, update the feature (\"technical\"), and aggregate into companies\n",
    "from bpideep.process_scraped_data import companies_technical_stats_with_founders_features, update_technical\n",
    "df_employees_full = update_technical(df_employees, df_founders)\n",
    "df_companies_stats_with_founders_features = companies_technical_stats_with_founders_features(df_employees_full)\n",
    "df_companies_stats_with_founders_features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T11:30:44.704886Z",
     "start_time": "2020-12-16T11:30:44.177815Z"
    }
   },
   "outputs": [],
   "source": [
    "# Last optional step: merge the DF with new company features with the dealroom df (partially preprocessed above)\n",
    "import pandas as pd\n",
    "from bpideep.process_scraped_data import merge_initial_companies_with_founder\n",
    "# df_full = pd.read_csv('../bpideep/rawdata/demo_data.csv')\n",
    "final = merge_initial_companies_with_founder(new_data, df_companies_stats_with_founders_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T22:03:54.502972Z",
     "start_time": "2020-12-16T22:03:54.474305Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9 entries, 0 to 8\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    9 non-null      int64  \n",
      " 1   name                  9 non-null      object \n",
      " 2   total_funding_source  9 non-null      int64  \n",
      " 3   employees             9 non-null      object \n",
      " 4   employees_latest      8 non-null      float64\n",
      " 5   launch_year           9 non-null      int64  \n",
      " 6   growth_stage          9 non-null      object \n",
      " 7   linkedin_url          9 non-null      object \n",
      " 8   industries            9 non-null      object \n",
      " 9   investors             9 non-null      object \n",
      " 10  nb_patents            9 non-null      int64  \n",
      " 11  age                   9 non-null      int64  \n",
      " 12  investors_type        9 non-null      object \n",
      " 13  health_industry       9 non-null      int64  \n",
      "dtypes: float64(1), int64(6), object(7)\n",
      "memory usage: 1.1+ KB\n"
     ]
    }
   ],
   "source": [
    "new_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always best to have real data, even approximated and filled manually. \n",
    "The new function GetCleanData.get_clean_data() is built to get a Dealroom database filled with some manual imputings (LinkedIn scraping + manual info collection) for the columns needed for the model. \n",
    "\n",
    "NB : due to the short time we had, the growth stage imputing was included in the GetCleanData.get_clean_data(). It would be better if it is part of the pipeline so that any dataset of new observations can directly be handled by the pipeline. \n",
    "\n",
    "For the other cells, the pipeline will be able to fill in the missing data, using the average or most frequent data in the training set. It is allowed to have empty or NaN cells for the following fields:\n",
    " \n",
    "+ number of employees (column called : \"employees_latest\" in Dealroom and \"employees_clean\" in our function)\n",
    "+ age (created column called \"age\")\n",
    "+ nb_patents\n",
    "\n",
    "+ launch_year (column called : \"launch_year\" in Dealroom and \"lauch_year_clean\" in our function) -> if the imputing growth stage function is directly in the pipeline (not in our case so far)\n",
    "\n",
    "If you have empty cells in any other fields, the model will throw an error, so make sure to fill them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example, all 9 firms have a growth_stage indicated in Dealroom. So we can directly use the pipeline to predict their classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the main model to predict whether the company is deeptech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T09:48:56.126287Z",
     "start_time": "2020-12-16T09:48:56.119249Z"
    }
   },
   "source": [
    "Use the model already trained on our entire dataset (1332 observations) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T22:08:25.338499Z",
     "start_time": "2020-12-16T22:08:25.281889Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    " \n",
    "# Load pipeline from pickle file\n",
    "my_pipeline = pickle.load(open(\"../bpideep/bpideepmodelnew.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the Labels using the reloaded Model\n",
    "y_pred = my_pipeline.predict(final)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping and using text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input needs to have the following fields:\n",
    "[TODO]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then use the following functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the NLP model to predict whether the company is deeptech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the two predictions \"vote\" for final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
